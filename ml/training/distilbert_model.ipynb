{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b692ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.53.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-23.0.0-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.3-cp310-cp310-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.1-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl.metadata (77 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\srush\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.13.3-cp310-cp310-win_amd64.whl (456 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.7.1-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading pyarrow-23.0.0-cp310-cp310-win_amd64.whl (27.5 MB)\n",
      "   ---------------------------------------- 0.0/27.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/27.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/27.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/27.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/27.5 MB 699.0 kB/s eta 0:00:39\n",
      "    --------------------------------------- 0.5/27.5 MB 699.0 kB/s eta 0:00:39\n",
      "   - -------------------------------------- 0.8/27.5 MB 657.8 kB/s eta 0:00:41\n",
      "   - -------------------------------------- 0.8/27.5 MB 657.8 kB/s eta 0:00:41\n",
      "   - -------------------------------------- 1.0/27.5 MB 637.3 kB/s eta 0:00:42\n",
      "   - -------------------------------------- 1.3/27.5 MB 692.1 kB/s eta 0:00:38\n",
      "   -- ------------------------------------- 1.6/27.5 MB 723.4 kB/s eta 0:00:36\n",
      "   -- ------------------------------------- 1.6/27.5 MB 723.4 kB/s eta 0:00:36\n",
      "   -- ------------------------------------- 1.8/27.5 MB 745.8 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 2.1/27.5 MB 729.6 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 2.1/27.5 MB 729.6 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 2.6/27.5 MB 803.3 kB/s eta 0:00:32\n",
      "   --- ------------------------------------ 2.6/27.5 MB 803.3 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 2.9/27.5 MB 822.5 kB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 3.1/27.5 MB 809.5 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 3.1/27.5 MB 809.5 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 3.4/27.5 MB 802.1 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 3.7/27.5 MB 810.8 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 3.7/27.5 MB 810.8 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 3.9/27.5 MB 812.8 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 4.2/27.5 MB 819.7 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 4.5/27.5 MB 826.0 kB/s eta 0:00:28\n",
      "   ------ --------------------------------- 4.5/27.5 MB 826.0 kB/s eta 0:00:28\n",
      "   ------ --------------------------------- 4.7/27.5 MB 824.4 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 5.0/27.5 MB 827.4 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 5.0/27.5 MB 827.4 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 5.2/27.5 MB 815.3 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 5.2/27.5 MB 815.3 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 5.5/27.5 MB 808.6 kB/s eta 0:00:28\n",
      "   -------- ------------------------------- 5.8/27.5 MB 806.2 kB/s eta 0:00:27\n",
      "   -------- ------------------------------- 5.8/27.5 MB 806.2 kB/s eta 0:00:27\n",
      "   -------- ------------------------------- 5.8/27.5 MB 806.2 kB/s eta 0:00:27\n",
      "   -------- ------------------------------- 6.0/27.5 MB 780.4 kB/s eta 0:00:28\n",
      "   -------- ------------------------------- 6.0/27.5 MB 780.4 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 6.3/27.5 MB 770.2 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 6.3/27.5 MB 770.2 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 6.6/27.5 MB 768.5 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 6.6/27.5 MB 768.5 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 6.8/27.5 MB 765.4 kB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 7.1/27.5 MB 761.3 kB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 7.1/27.5 MB 761.3 kB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 7.1/27.5 MB 761.3 kB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 7.3/27.5 MB 747.6 kB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 7.3/27.5 MB 747.6 kB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 7.6/27.5 MB 736.4 kB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 7.6/27.5 MB 736.4 kB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 7.9/27.5 MB 728.4 kB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 7.9/27.5 MB 728.4 kB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 8.1/27.5 MB 720.0 kB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 8.1/27.5 MB 720.0 kB/s eta 0:00:27\n",
      "   ------------ --------------------------- 8.4/27.5 MB 719.3 kB/s eta 0:00:27\n",
      "   ------------ --------------------------- 8.7/27.5 MB 729.4 kB/s eta 0:00:26\n",
      "   ------------ --------------------------- 8.9/27.5 MB 737.2 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 9.2/27.5 MB 743.7 kB/s eta 0:00:25\n",
      "   ------------- -------------------------- 9.4/27.5 MB 749.0 kB/s eta 0:00:25\n",
      "   ------------- -------------------------- 9.4/27.5 MB 749.0 kB/s eta 0:00:25\n",
      "   -------------- ------------------------- 9.7/27.5 MB 744.7 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 9.7/27.5 MB 744.7 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.0/27.5 MB 746.1 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.0/27.5 MB 746.1 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 10.2/27.5 MB 740.5 kB/s eta 0:00:24\n",
      "   --------------- ------------------------ 10.7/27.5 MB 675.1 kB/s eta 0:00:25\n",
      "   --------------- ------------------------ 11.0/27.5 MB 689.3 kB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 11.3/27.5 MB 696.3 kB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 11.5/27.5 MB 702.4 kB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 11.8/27.5 MB 710.5 kB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 11.8/27.5 MB 710.5 kB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 12.1/27.5 MB 701.7 kB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 12.1/27.5 MB 701.7 kB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 12.3/27.5 MB 702.2 kB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 12.3/27.5 MB 702.2 kB/s eta 0:00:22\n",
      "   ------------------ --------------------- 12.8/27.5 MB 713.3 kB/s eta 0:00:21\n",
      "   ------------------ --------------------- 12.8/27.5 MB 713.3 kB/s eta 0:00:21\n",
      "   ------------------- -------------------- 13.4/27.5 MB 728.8 kB/s eta 0:00:20\n",
      "   ------------------- -------------------- 13.6/27.5 MB 738.3 kB/s eta 0:00:19\n",
      "   -------------------- ------------------- 14.2/27.5 MB 751.0 kB/s eta 0:00:18\n",
      "   -------------------- ------------------- 14.2/27.5 MB 751.0 kB/s eta 0:00:18\n",
      "   -------------------- ------------------- 14.4/27.5 MB 753.1 kB/s eta 0:00:18\n",
      "   --------------------- ------------------ 14.9/27.5 MB 768.2 kB/s eta 0:00:17\n",
      "   --------------------- ------------------ 14.9/27.5 MB 768.2 kB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 15.2/27.5 MB 765.0 kB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 15.2/27.5 MB 765.0 kB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 15.5/27.5 MB 762.0 kB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 15.5/27.5 MB 762.0 kB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 15.7/27.5 MB 760.3 kB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 15.7/27.5 MB 760.3 kB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 16.0/27.5 MB 760.3 kB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 16.3/27.5 MB 759.2 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 16.5/27.5 MB 764.8 kB/s eta 0:00:15\n",
      "   ------------------------ --------------- 16.8/27.5 MB 770.4 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 17.0/27.5 MB 777.5 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 17.3/27.5 MB 782.9 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 17.6/27.5 MB 785.9 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 17.8/27.5 MB 786.6 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 17.8/27.5 MB 786.6 kB/s eta 0:00:13\n",
      "   -------------------------- ------------- 18.1/27.5 MB 784.7 kB/s eta 0:00:13\n",
      "   -------------------------- ------------- 18.4/27.5 MB 787.0 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 18.4/27.5 MB 787.0 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 18.4/27.5 MB 787.0 kB/s eta 0:00:12\n",
      "   --------------------------- ------------ 18.6/27.5 MB 779.8 kB/s eta 0:00:12\n",
      "   --------------------------- ------------ 18.9/27.5 MB 782.7 kB/s eta 0:00:12\n",
      "   --------------------------- ------------ 19.1/27.5 MB 785.9 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 19.1/27.5 MB 785.9 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 19.4/27.5 MB 784.1 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 19.4/27.5 MB 784.1 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 19.7/27.5 MB 780.8 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 19.9/27.5 MB 780.6 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 19.9/27.5 MB 780.6 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 20.2/27.5 MB 777.0 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 20.2/27.5 MB 777.0 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 20.2/27.5 MB 777.0 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 20.4/27.5 MB 774.0 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 20.4/27.5 MB 774.0 kB/s eta 0:00:10\n",
      "   ------------------------------ --------- 20.7/27.5 MB 771.2 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 21.0/27.5 MB 772.8 kB/s eta 0:00:09\n",
      "   ------------------------------- -------- 21.5/27.5 MB 781.5 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 22.0/27.5 MB 793.4 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 22.3/27.5 MB 798.5 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 22.5/27.5 MB 800.7 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 22.5/27.5 MB 800.7 kB/s eta 0:00:07\n",
      "   --------------------------------- ------ 22.8/27.5 MB 800.2 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 23.1/27.5 MB 800.7 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 23.3/27.5 MB 802.4 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 23.3/27.5 MB 802.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 23.6/27.5 MB 803.2 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 23.6/27.5 MB 803.2 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 23.9/27.5 MB 801.5 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 23.9/27.5 MB 801.5 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 24.1/27.5 MB 798.5 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 24.4/27.5 MB 800.6 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 24.6/27.5 MB 803.6 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 24.9/27.5 MB 810.7 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 25.2/27.5 MB 813.2 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 25.2/27.5 MB 813.2 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 25.4/27.5 MB 813.9 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 25.7/27.5 MB 813.9 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 26.0/27.5 MB 814.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 26.0/27.5 MB 814.8 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 26.5/27.5 MB 823.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 26.7/27.5 MB 828.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  27.0/27.5 MB 832.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  27.3/27.5 MB 834.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 27.5/27.5 MB 826.3 kB/s  0:00:33\n",
      "Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl (31 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "\n",
      "  Attempting uninstall: pyarrow\n",
      "\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   ------ ---------------------------------  2/13 [propcache]\n",
      "   ------------ ---------------------------  4/13 [frozenlist]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------------- ------------------  7/13 [aiohappyeyeballs]\n",
      "   ------------------------ ---------------  8/13 [yarl]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   ------------------------------ --------- 10/13 [aiosignal]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ---------------------------------------- 13/13 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 async-timeout-5.0.1 datasets-4.5.0 dill-0.4.0 frozenlist-1.8.0 multidict-6.7.1 multiprocess-0.70.18 propcache-0.4.1 pyarrow-23.0.0 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\srush\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~yarrow'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c92700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srush\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83022dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: (300000, 46)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/jigsaw-unintended-bias-train.csv\")\n",
    "\n",
    "df[\"toxicity\"] = df[\"toxic\"] >= 0.5\n",
    "\n",
    "# Sample 300k for CPU training\n",
    "df_sample = df.sample(n=300000, random_state=42)\n",
    "\n",
    "print(\"Sample shape:\", df_sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e33b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sample[\"comment_text\"],\n",
    "    df_sample[\"toxicity\"],\n",
    "    test_size=0.2,\n",
    "    stratify=df_sample[\"toxicity\"],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6d36ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcac2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete \n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch_texts):\n",
    "    return tokenizer(\n",
    "        batch_texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(X_train)\n",
    "test_encodings = tokenize(X_test)\n",
    "\n",
    "print(\"Tokenization complete \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff766d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.tolist()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483684f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created \n"
     ]
    }
   ],
   "source": [
    "train_dataset = ToxicDataset(train_encodings, y_train)\n",
    "test_dataset = ToxicDataset(test_encodings, y_test)\n",
    "\n",
    "print(\"Datasets created \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca3b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 100/100 [00:00<00:00, 361.01it/s, Materializing param=distilbert.transformer.layer.5.sa_layer_norm.weight]   \n",
      "\u001b[1mDistilBertForSequenceClassification LOAD REPORT\u001b[0m from: distilbert-base-uncased\n",
      "Key                     | Status     | \n",
      "------------------------+------------+-\n",
      "vocab_projector.bias    | UNEXPECTED | \n",
      "vocab_layer_norm.weight | UNEXPECTED | \n",
      "vocab_transform.weight  | UNEXPECTED | \n",
      "vocab_transform.bias    | UNEXPECTED | \n",
      "vocab_layer_norm.bias   | UNEXPECTED | \n",
      "pre_classifier.weight   | MISSING    | \n",
      "classifier.bias         | MISSING    | \n",
      "classifier.weight       | MISSING    | \n",
      "pre_classifier.bias     | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=1  # Binary classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a09dbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.53.2)\n",
      "Collecting transformers[torch]\n",
      "  Downloading transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting huggingface-hub<2.0,>=1.3.0 (from transformers[torch])\n",
      "  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers[torch])\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typer-slim (from transformers[torch])\n",
      "  Downloading typer_slim-0.23.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.4 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (2.7.1)\n",
      "Collecting accelerate>=1.1.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (2025.7.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=1.3.0->transformers[torch])\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (0.16.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\srush\\appdata\\roaming\\python\\python310\\site-packages (from accelerate>=1.1.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.4->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.4->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.4->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=2.4->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\srush\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.4->transformers[torch]) (3.0.3)\n",
      "Collecting typer>=0.23.0 (from typer-slim->transformers[torch])\n",
      "  Downloading typer-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer>=0.23.0->typer-slim->transformers[torch]) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer>=0.23.0->typer-slim->transformers[torch]) (14.1.0)\n",
      "Collecting annotated-doc>=0.0.2 (from typer>=0.23.0->typer-slim->transformers[torch])\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->typer>=0.23.0->typer-slim->transformers[torch]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->typer>=0.23.0->typer-slim->transformers[torch]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\srush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.0->typer-slim->transformers[torch]) (0.1.2)\n",
      "Downloading transformers-5.1.0-py3-none-any.whl (10.3 MB)\n",
      "   ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.3 MB 541.6 kB/s eta 0:00:19\n",
      "   -- ------------------------------------- 0.5/10.3 MB 541.6 kB/s eta 0:00:19\n",
      "   -- ------------------------------------- 0.5/10.3 MB 541.6 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 0.8/10.3 MB 493.7 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 0.8/10.3 MB 493.7 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 0.8/10.3 MB 493.7 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 1.0/10.3 MB 453.5 kB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 1.0/10.3 MB 453.5 kB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 1.3/10.3 MB 469.4 kB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 1.3/10.3 MB 469.4 kB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 1.3/10.3 MB 469.4 kB/s eta 0:00:20\n",
      "   ------ --------------------------------- 1.6/10.3 MB 490.5 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 1.8/10.3 MB 513.7 kB/s eta 0:00:17\n",
      "   ------- -------------------------------- 1.8/10.3 MB 513.7 kB/s eta 0:00:17\n",
      "   ------- -------------------------------- 1.8/10.3 MB 513.7 kB/s eta 0:00:17\n",
      "   -------- ------------------------------- 2.1/10.3 MB 522.0 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.4/10.3 MB 545.6 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.4/10.3 MB 545.6 kB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 2.6/10.3 MB 561.3 kB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 2.9/10.3 MB 586.6 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 3.1/10.3 MB 611.1 kB/s eta 0:00:12\n",
      "   ------------- -------------------------- 3.4/10.3 MB 641.2 kB/s eta 0:00:11\n",
      "   -------------- ------------------------- 3.7/10.3 MB 663.0 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 3.9/10.3 MB 678.9 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 4.2/10.3 MB 707.0 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 4.7/10.3 MB 766.8 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 5.0/10.3 MB 784.5 kB/s eta 0:00:07\n",
      "   -------------------- ------------------- 5.2/10.3 MB 795.0 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.5/10.3 MB 806.6 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.5/10.3 MB 806.6 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.8/10.3 MB 809.9 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 6.0/10.3 MB 814.8 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 6.0/10.3 MB 814.8 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 6.3/10.3 MB 810.7 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.3/10.3 MB 810.7 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.6/10.3 MB 802.1 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.8/10.3 MB 811.3 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.1/10.3 MB 810.8 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.3/10.3 MB 820.6 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.3/10.3 MB 820.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.6/10.3 MB 822.7 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 7.9/10.3 MB 821.9 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.9/10.3 MB 821.9 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.1/10.3 MB 822.5 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.4/10.3 MB 821.7 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.7/10.3 MB 833.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.9/10.3 MB 836.3 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.9/10.3 MB 836.3 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.2/10.3 MB 830.3 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.2/10.3 MB 830.3 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.4/10.3 MB 824.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.0/10.3 MB 844.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.3/10.3 MB 861.5 kB/s  0:00:12\n",
      "Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "   ---------------------------------------- 0.0/553.3 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 262.1/553.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 553.3/553.3 kB 1.1 MB/s  0:00:00\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.9 MB 762.0 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 882.6 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 882.6 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.9 MB 751.1 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.9 MB 751.1 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.9 MB 751.1 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.9 MB 751.1 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.9 MB 751.1 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.9 MB 751.1 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.9 MB 751.1 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.9 MB 751.1 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.3/2.9 MB 372.9 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 1.6/2.9 MB 443.9 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 2.4/2.9 MB 677.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 686.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 686.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 687.7 kB/s  0:00:04\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 929.6 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.5/2.7 MB 929.6 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 958.5 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.0/2.7 MB 986.7 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.3/2.7 MB 944.7 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.3/2.7 MB 944.7 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.6/2.7 MB 901.5 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.6/2.7 MB 901.5 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.8/2.7 MB 824.8 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 945.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 1.0 MB/s  0:00:02\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading typer_slim-0.23.0-py3-none-any.whl (3.4 kB)\n",
      "Downloading typer-0.23.0-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Installing collected packages: hf-xet, annotated-doc, typer, typer-slim, huggingface-hub, tokenizers, accelerate, transformers\n",
      "\n",
      "  Attempting uninstall: typer\n",
      "\n",
      "    Found existing installation: typer 0.19.2\n",
      "\n",
      "   ---------- ----------------------------- 2/8 [typer]\n",
      "    Uninstalling typer-0.19.2:\n",
      "   ---------- ----------------------------- 2/8 [typer]\n",
      "      Successfully uninstalled typer-0.19.2\n",
      "   ---------- ----------------------------- 2/8 [typer]\n",
      "   ---------- ----------------------------- 2/8 [typer]\n",
      "   ---------- ----------------------------- 2/8 [typer]\n",
      "   ---------- ----------------------------- 2/8 [typer]\n",
      "  Attempting uninstall: huggingface-hub\n",
      "   ---------- ----------------------------- 2/8 [typer]\n",
      "    Found existing installation: huggingface-hub 0.33.4\n",
      "   ---------- ----------------------------- 2/8 [typer]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "    Uninstalling huggingface-hub-0.33.4:\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "      Successfully uninstalled huggingface-hub-0.33.4\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "  Attempting uninstall: tokenizers\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "   -------------------- ------------------- 4/8 [huggingface-hub]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------- -------------- 5/8 [tokenizers]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "  Attempting uninstall: transformers\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "    Found existing installation: transformers 4.53.2\n",
      "   ------------------------------ --------- 6/8 [accelerate]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "    Uninstalling transformers-4.53.2:\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "      Successfully uninstalled transformers-4.53.2\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ---------------------------------------- 8/8 [transformers]\n",
      "\n",
      "Successfully installed accelerate-1.12.0 annotated-doc-0.0.4 hf-xet-1.2.0 huggingface-hub-1.4.1 tokenizers-0.22.2 transformers-5.1.0 typer-0.23.0 typer-slim-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\srush\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 5.0.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.1.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch] --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f61bf5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    report_to=\"none\"   # <-- string, not None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73722c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.sigmoid(torch.tensor(logits)).numpy().flatten()\n",
    "    return {\n",
    "        \"roc_auc\": roc_auc_score(labels, probs)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73e19101",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba65e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srush\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 27:36:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.065885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.057829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.049354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.052247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.049822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.045845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.044772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.052062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.045873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.050831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.050803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.050274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.049005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.043612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.054162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.046223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.046077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.044598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.046839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.047365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.043573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.043304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.044726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.045952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.046658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.048333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.049555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.045207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.045710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.044355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.043946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.040365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.044107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.042919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.044203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.043966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.047171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.042545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.041681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.043035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.039091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.039506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.040069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.042439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.043147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.039614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.043998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.045771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.040963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.041512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.044072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.040470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.039111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.038719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.040480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.038411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.038841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.039052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.040265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.040162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30000, training_loss=0.04500806573232015, metrics={'train_runtime': 99375.0734, 'train_samples_per_second': 2.415, 'train_steps_per_second': 0.302, 'total_flos': 7947902177280000.0, 'train_loss': 0.04500806573232015, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16a6888",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eaf059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 104/104 [00:00<00:00, 240.19it/s, Materializing param=pre_classifier.weight]                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully \n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "import torch\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"./results/distilbert_final\"\n",
    ")\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    \"./results/distilbert_final\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc63df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fa2d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data recreated \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/jigsaw-unintended-bias-train.csv\")\n",
    "\n",
    "df[\"toxicity\"] = df[\"toxic\"] >= 0.5\n",
    "\n",
    "# SAME sample as before\n",
    "df_sample = df.sample(n=300000, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sample[\"comment_text\"],\n",
    "    df_sample[\"toxicity\"],\n",
    "    test_size=0.2,\n",
    "    stratify=df_sample[\"toxicity\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data recreated \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd357cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    \"./results/distilbert_final\"\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    X_test.tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c78b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset ready \n"
     ]
    }
   ],
   "source": [
    "class ToxicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.tolist()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "test_dataset = ToxicDataset(test_encodings, y_test)\n",
    "\n",
    "print(\"Test dataset ready \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0456a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 104/104 [00:00<00:00, 146.07it/s, Materializing param=pre_classifier.weight]                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded \n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"./results/distilbert_final\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57159b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = {k: v for k, v in batch.items() if k != \"labels\"}\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits.squeeze()\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        all_probs.extend(probs.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "accuracy = accuracy_score(all_labels, np.array(all_probs) > 0.5)\n",
    "\n",
    "print(\"DistilBERT ROC-AUC:\", round(roc_auc, 4))\n",
    "print(\"DistilBERT Accuracy:\", round(accuracy, 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
