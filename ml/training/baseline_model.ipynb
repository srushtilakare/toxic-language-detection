{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f3d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686fca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1902194, 46)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/jigsaw-unintended-bias-train.csv\")\n",
    "\n",
    "# Create binary label\n",
    "df[\"toxicity\"] = df[\"toxic\"] >= 0.5\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ec7803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1521755\n",
      "Test size: 380439\n"
     ]
    }
   ],
   "source": [
    "X = df[\"comment_text\"]\n",
    "y = df[\"toxicity\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38a6142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (1521755, 50000)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1,2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", X_train_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efcaa8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model trained\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(\n",
    "    loss=\"log_loss\",        # logistic regression\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=20,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Baseline model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff8cc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline ROC-AUC: 0.9147\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Baseline ROC-AUC:\", round(roc_auc, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6625337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to test dataframe\n",
    "test_df = pd.DataFrame({\n",
    "    \"comment_text\": X_test,\n",
    "    \"true_label\": y_test,\n",
    "    \"pred_proba\": y_pred_proba\n",
    "})\n",
    "\n",
    "# Add identity columns from original df\n",
    "identity_columns = [\n",
    "    'male', 'female', 'muslim', 'jewish',\n",
    "    'black', 'white', 'christian',\n",
    "    'homosexual_gay_or_lesbian'\n",
    "]\n",
    "\n",
    "for col in identity_columns:\n",
    "    test_df[col] = df.loc[X_test.index, col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee35bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall ROC-AUC: 0.9147\n",
      "\n",
      "Subgroup AUC:\n",
      "male: 0.8551\n",
      "female: 0.8512\n",
      "muslim: 0.7857\n",
      "jewish: 0.8264\n",
      "black: 0.7536\n",
      "white: 0.7736\n",
      "christian: 0.8645\n",
      "homosexual_gay_or_lesbian: 0.7483\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall ROC-AUC:\", round(roc_auc, 4))\n",
    "print(\"\\nSubgroup AUC:\")\n",
    "\n",
    "for col in identity_columns:\n",
    "    subgroup = test_df[test_df[col] > 0.5]\n",
    "    \n",
    "    if len(subgroup) > 100:  # avoid tiny groups\n",
    "        auc = roc_auc_score(subgroup[\"true_label\"], subgroup[\"pred_proba\"])\n",
    "        print(f\"{col}: {round(auc, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd4c583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model trained \n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# LinearSVC doesn't give probabilities â†’ we calibrate it\n",
    "svm = LinearSVC(class_weight=\"balanced\")\n",
    "\n",
    "calibrated_svm = CalibratedClassifierCV(svm)\n",
    "\n",
    "calibrated_svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"SVM model trained \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e438b294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ROC-AUC: 0.9326\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba_svm = calibrated_svm.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_proba_svm)\n",
    "\n",
    "print(\"SVM ROC-AUC:\", round(roc_auc_svm, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac991b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "test_df[\"svm_pred_proba\"] = y_pred_proba_svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82af3e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall SVM ROC-AUC: 0.9326\n",
      "\n",
      "SVM Subgroup AUC:\n",
      "male: 0.8843\n",
      "female: 0.8826\n",
      "muslim: 0.8083\n",
      "jewish: 0.8523\n",
      "black: 0.7926\n",
      "white: 0.7964\n",
      "christian: 0.8802\n",
      "homosexual_gay_or_lesbian: 0.7631\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall SVM ROC-AUC:\", round(roc_auc_svm, 4))\n",
    "print(\"\\nSVM Subgroup AUC:\")\n",
    "\n",
    "for col in identity_columns:\n",
    "    subgroup = test_df[test_df[col] > 0.5]\n",
    "    \n",
    "    if len(subgroup) > 100:\n",
    "        auc = roc_auc_score(subgroup[\"true_label\"], \n",
    "                            subgroup[\"svm_pred_proba\"])\n",
    "        print(f\"{col}: {round(auc, 4)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
